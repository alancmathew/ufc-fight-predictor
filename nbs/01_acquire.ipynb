{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b529969-d1f5-49b5-bea8-f36f33bf66d0",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86d6700-e4e7-463d-b00e-5fe7771b30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import httpx\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0e6e3a-d9f6-4105-8155-a0a8a17c79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmap = lambda funcion, iterable: list(map(funcion, iterable))\n",
    "lfilter = lambda funcion, iterable: list(filter(funcion, iterable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0926e55c-745b-491b-921c-c71591c98333",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "raw_dir = os.path.join(data_dir, \"raw\")\n",
    "mid_dir = os.path.join(data_dir, \"mid\")\n",
    "raw_csv_dir = os.path.join(raw_dir, \"csv\")\n",
    "html_dir = os.path.join(raw_dir, \"html\")\n",
    "completed_html_dir = os.path.join(html_dir, \"completed\")\n",
    "upcoming_html_dir = os.path.join(html_dir, \"upcoming\")\n",
    "fighterlist_html_dir = os.path.join(html_dir, \"fighterlist\")\n",
    "fighters_html_dir = os.path.join(html_dir, \"fighters\")\n",
    "completed_eventlist_html_dir = os.path.join(completed_html_dir, \"eventlist\")\n",
    "completed_events_html_dir = os.path.join(completed_html_dir, \"events\")\n",
    "completed_fights_html_dir = os.path.join(completed_html_dir, \"fights\")\n",
    "upcoming_eventlist_html_dir = os.path.join(upcoming_html_dir, \"eventlist\")\n",
    "upcoming_events_html_dir = os.path.join(upcoming_html_dir, \"events\")\n",
    "upcoming_fights_html_dir = os.path.join(upcoming_html_dir, \"fights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb843a33-40a1-43df-b2d1-8f0b67641258",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [raw_csv_dir, fighters_html_dir, fighterlist_html_dir,\n",
    "        completed_eventlist_html_dir, \n",
    "        completed_events_html_dir,\n",
    "        upcoming_eventlist_html_dir, upcoming_events_html_dir,\n",
    "       completed_fights_html_dir, upcoming_fights_html_dir]\n",
    "\n",
    "for folderpath in dirs:\n",
    "    os.makedirs(folderpath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debac4c1-8ec4-42dc-85a0-e9c679af2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(html_str: str, filename: str, folderpath: str = html_dir) -> None:\n",
    "    os.makedirs(folderpath, exist_ok=True)\n",
    "    \n",
    "    filepath = os.path.join(folderpath, filename)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2528cdd8-bed1-4b60-9c6d-e68b5b08ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_get_html(url: str, filename: str, folderpath: str = html_dir, session=None) -> str:\n",
    "    if session:\n",
    "        r = session.get(url)\n",
    "    else:\n",
    "        r = httpx.get(url)\n",
    "        \n",
    "    if r.status_code == 200:\n",
    "        html_str = r.text\n",
    "        save_html(html_str, filename, folderpath)\n",
    "        return html_str\n",
    "    else:\n",
    "        print(f\"Unable to get: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95aa9f5-d388-4305-9466-7c3a29017c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def download_sequential_pages(first_url:str, folderpath: str = html_dir) -> None:\n",
    "    with httpx.Client() as session:\n",
    "        filename = first_url.split(\"?\")[1].replace(\"&\",\"-\").replace(\"=\",\"\")\n",
    "        html = download_get_html(first_url, f\"{filename}-page01.html\", folderpath, session)\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        page_links = soup.find_all(\"a\", class_=\"b-statistics__paginate-link\")\n",
    "\n",
    "        page_nums = [a.text.strip() for a in page_links]\n",
    "        \n",
    "        for idx, num in enumerate(page_nums):\n",
    "            try:\n",
    "                page_nums[idx] = int(num)\n",
    "            except ValueError:\n",
    "                page_nums.remove(num)\n",
    "\n",
    "        num_pages = max(page_nums)\n",
    "        \n",
    "        \n",
    "        if num_pages != 1:\n",
    "            inter = \"&\" if \"?\" in first_url else \"?\"\n",
    "            for page_num in tqdm(range(2, num_pages+1)):\n",
    "                url = f\"{first_url}{inter}page={page_num:02}\"\n",
    "                filename = url.split(\"?\")[1].replace(\"&\",\"-\").replace(\"=\",\"\")\n",
    "                if not os.path.exists(os.path.join(folderpath, f\"{filename}.html\")):\n",
    "                    _ = download_get_html(url, f\"{filename}.html\", folderpath, session)\n",
    "                    time.sleep(random.randint(5000, 10000)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc8c856-da15-46af-a06e-53898a735b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pages(urls: list[str], outfolderdir: str) -> None:\n",
    "    fail_score = 0\n",
    "    reached_not_downloaded = False\n",
    "    session = httpx.Client()\n",
    "    for idx, url in enumerate(tqdm(urls)):\n",
    "        if reached_not_downloaded and (idx != 0) and (idx%25 == 0):\n",
    "            session.close()\n",
    "            time.sleep(random.randint(60000, 300000)/1000)\n",
    "            print(\"Switching session\")\n",
    "            session = httpx.Client()\n",
    "        unique_id = os.path.split(url)[1]\n",
    "        if not os.path.exists(os.path.join(outfolderdir, f\"{unique_id}.html\")):\n",
    "            reached_not_downloaded = True\n",
    "            try:\n",
    "                download_get_html(url, f\"{unique_id}.html\", outfolderdir, session)\n",
    "                if fail_score > 0:\n",
    "                    fail_score -= 1\n",
    "            except:\n",
    "                fail_score += 2\n",
    "                print(f\"Network request unsuccessful. Fail score: {fail_score}\")\n",
    "                session.close()\n",
    "                \n",
    "                if fail_score >= 20:\n",
    "                    break\n",
    "                session = httpx.Client()\n",
    "            finally:\n",
    "                time.sleep(random.randint(10000, 20000)/1000)\n",
    "        else:\n",
    "            reached_not_downloaded = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6d7b4-fb18-490c-a059-4ab8db491625",
   "metadata": {},
   "source": [
    "### Get Events list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee0574-d0b8-46d0-99b7-e2bf05cbee93",
   "metadata": {},
   "source": [
    "#### Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c163a67-c788-44e7-96bf-02725d0ea741",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_first_url = \"http://ufcstats.com/statistics/events/completed\"\n",
    "download_sequential_pages(completed_first_url, completed_eventlist_html_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3919d-daff-4a18-a7f2-23ca9821d7ea",
   "metadata": {},
   "source": [
    "#### Upcoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad09cf-d8ad-4eee-b728-ddf291f45a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_first_url = \"http://ufcstats.com/statistics/events/upcoming\"\n",
    "download_sequential_pages(upcoming_first_url, upcoming_eventlist_html_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6f6db-614e-4085-ae3a-903bdb1bd0f0",
   "metadata": {},
   "source": [
    "### Parse Events list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5a1bcc-30b1-4d5e-b670-673bb5ef7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_list(eventlist_html_dir: str) -> list[str]:\n",
    "    \n",
    "    def extract_event_data(row):\n",
    "        features = {\n",
    "            \"name\": None,\n",
    "            \"date\": None,\n",
    "            \"location\": None,\n",
    "            \"url\": None\n",
    "        }\n",
    "        \n",
    "        a_elem = row.find(\"a\", class_=\"b-link b-link_style_black\")\n",
    "        features[\"name\"], features[\"url\"] = a_elem.text.strip(), a_elem[\"href\"]\n",
    "        features[\"date\"] = row.find(\"span\", class_=\"b-statistics__date\").text.strip()\n",
    "        features[\"location\"] = row.find_all(\"td\")[1].text.strip()\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    events_list = []\n",
    "    page_files = sorted(lfilter(lambda s: s.endswith(\".html\"), os.listdir(eventlist_html_dir)))\n",
    "    for file in page_files:\n",
    "        filepath = os.path.join(eventlist_html_dir, file)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            eventlistpage_html = f.read()\n",
    "            assert eventlistpage_html != \"\"\n",
    "            soup = BeautifulSoup(eventlistpage_html)\n",
    "            row_elems = soup.find(\"tbody\").find_all(\"tr\", class_=\"b-statistics__table-row\")\n",
    "            row_elems = lfilter(lambda r: len(r.find_all(\"a\", class_=\"b-link b-link_style_black\")) != 0, row_elems)\n",
    "            events_sublist = lmap(extract_event_data, row_elems)\n",
    "            events_list.extend(events_sublist)\n",
    "            \n",
    "    return events_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe8c77a-3c72-46a7-a8c8-d45b87b3cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(thelist: list[str], filepath: str) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for item in thelist:\n",
    "            f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000bc69a-ef0f-497d-ba4f-09e772087c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(filepath: str) -> list[str]:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79afaf2-632b-45e6-85ae-8841220e25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_events_df(eventlist_html_dir: str, outfilename: str) -> pd.DataFrame:\n",
    "    events_list = get_events_list(eventlist_html_dir)\n",
    "    print(f\"Event list length: {len(events_list)}\")\n",
    "    events_df = pd.DataFrame(events_list)\n",
    "    filepath = os.path.join(raw_csv_dir, outfilename)\n",
    "    events_df.to_csv(filepath, index=False)\n",
    "    return events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263513dc-559a-4475-bb3a-bfc358e68255",
   "metadata": {},
   "source": [
    "#### Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf88b00-43c6-44e9-b0c8-1699b448401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_events_df = save_events_df(completed_eventlist_html_dir, \"completed_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38024ec-c6d6-4671-b909-f2b2e0ec8bb5",
   "metadata": {},
   "source": [
    "#### Upcoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d73776-18a5-4404-89a7-60b4ca636e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_events_df = save_events_df(upcoming_eventlist_html_dir, \"upcoming_event.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e6701-4889-475f-9206-16b07a4ef6b3",
   "metadata": {},
   "source": [
    "### Get Event pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4aabe55-513f-4b4f-ac3f-9d4f2a804711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_event_pages(event_urls: list[str], outfolderpath: str) -> None:\n",
    "    with httpx.Client() as s:\n",
    "        for url in event_urls:\n",
    "            event_id = os.path.split(url)[1]\n",
    "            if not os.path.exists(os.path.join(outfolderpath, f\"{event_id}.html\")):\n",
    "                download_get_html(url, f\"{event_id}.html\", outfolderpath, s)\n",
    "                time.sleep(random.randint(10000, 20000)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f48a08-16e7-4377-bf19-a2c337786e3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8dede-fb72-4e7a-9def-317ff0726041",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_event_urls = completed_events_df[\"url\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f7ab0-36ff-464f-b796-061db6ee49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pages(completed_event_urls, completed_events_html_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8dcd83-a449-42ec-af5c-c2892ef90e20",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Upcoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f6022-7b5b-4560-acee-69265fb8999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_event_urls = upcoming_events_df[\"url\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b4e5d-8d3f-4ef3-91e6-745f2662cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pages(upcoming_event_urls, upcoming_events_html_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf70345-97fc-4223-a265-1b13faad5df8",
   "metadata": {},
   "source": [
    "### Parse Fights list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f8b90e3-c136-4f8c-b4cf-296725008bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fight_urls(event_html_filepath: str):\n",
    "    \n",
    "    with open(event_html_filepath, \"r\") as f:\n",
    "        html_str = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html_str, features=\"lxml\")\n",
    "    table = soup.find(\"table\")\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    headers = [key for key in map(lambda x: x.text.strip(), table.find(\"thead\").find_all(\"th\"))]\n",
    "\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "    \n",
    "    for row in rows:\n",
    "        for col, elem in zip(headers, row.find_all(\"td\")):\n",
    "            if col == \"Weight class\":\n",
    "                p_elem = elem.find(\"p\")\n",
    "                val = p_elem.text.strip()\n",
    "                data_list.append((row[\"data-link\"], val))\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd437dd-2efb-4458-89ad-c6c88c435c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fight_urls(events_html_dir: str, outfilename: str) -> list[str]:\n",
    "    event_files = lfilter(lambda x: x.endswith(\".html\"), os.listdir(events_html_dir))\n",
    "    \n",
    "    fight_urls_list = []\n",
    "    for filename in tqdm(event_files):\n",
    "        filepath = os.path.join(events_html_dir, filename)\n",
    "        fight_urls_sublist = extract_fight_urls(filepath)\n",
    "        fight_urls_list.extend(fight_urls_sublist)\n",
    "        \n",
    "    print(f\"Fight urls list length: {len(fight_urls_list)}\")\n",
    "    df = pd.DataFrame(fight_urls_list, columns=[\"Fight Url\", \"Weight Class\"])\n",
    "    filepath = os.path.join(raw_csv_dir, outfilename)\n",
    "    # write_list_to_file(fight_urls_list, filepath)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    return df[\"Fight Url\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb4c35b-d714-4e51-97b9-d0c5eeb57cd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d332831-d8bb-4f4e-8ea7-722d238ae42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_fight_urls_list = save_fight_urls(completed_events_html_dir, \"completed_fight_urls.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef7e6d9-2a72-4785-9650-6a1110840067",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Upcoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb9eae-3ccc-4ab8-9de4-08fe4d9e0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_fight_urls_list = save_fight_urls(upcoming_events_html_dir, \"upcoming_fight_urls.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2a1bf-b6bf-44dc-9dd6-af591bf218f4",
   "metadata": {},
   "source": [
    "### Get Fight pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd595467-4609-4684-bc76-1c8bd595ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(raw_csv_dir, \"completed_fight_urls.csv\")\n",
    "completed_fight_urls_list = pd.read_csv(filepath)[\"Fight Url\"]\n",
    "\n",
    "filepath = os.path.join(raw_csv_dir, \"upcoming_fight_urls.csv\")\n",
    "upcoming_fight_urls_list = pd.read_csv(filepath)[\"Fight Url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3134ee-94cc-4441-a3d4-d8f77023b001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_fight_pages(fight_urls: list[str], outfolderdir: str) -> None:\n",
    "    fail_score = 0\n",
    "    reached_not_downloaded = False\n",
    "    session = httpx.Client()\n",
    "    for idx, url in enumerate(tqdm(fight_urls)):\n",
    "        if reached_not_downloaded and (idx != 0) and (idx%25 == 0):\n",
    "            session.close()\n",
    "            time.sleep(random.randint(60000, 300000)/1000)\n",
    "            print(\"Switching session\")\n",
    "            session = httpx.Client()\n",
    "        fight_id = os.path.split(url)[1]\n",
    "        if not os.path.exists(os.path.join(outfolderdir, f\"{fight_id}.html\")):\n",
    "            reached_not_downloaded = True\n",
    "            try:\n",
    "                download_get_html(url, f\"{fight_id}.html\", outfolderdir, session)\n",
    "                if fail_score > 0:\n",
    "                    fail_score -= 1\n",
    "            except:\n",
    "                fail_score += 2\n",
    "                print(f\"Network request unsuccessful. Fail score: {fail_score}\")\n",
    "                session.close()\n",
    "                \n",
    "                if fail_score >= 20:\n",
    "                    break\n",
    "                session = httpx.Client()\n",
    "            finally:\n",
    "                time.sleep(random.randint(10000, 20000)/1000)\n",
    "        else:\n",
    "            reached_not_downloaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ff217-9aac-4091-803f-14a36e6f311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pages(completed_fight_urls_list, completed_fights_html_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0623ee1-186a-4262-b33a-8a500d9d0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pages(upcoming_fight_urls_list, upcoming_fights_html_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c37cc5-bd92-43d2-a4f1-aaf13629251c",
   "metadata": {},
   "source": [
    "### Get Fighter pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "574f86fa-345b-4bfa-9d68-81b87fd0863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 30519.88it/s]\n",
      "  4%|▍         | 1/26 [00:00<00:11,  2.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 26529.44it/s]\n",
      "  8%|▊         | 2/26 [00:00<00:11,  2.03it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 10600.60it/s]\n",
      " 12%|█▏        | 3/26 [00:01<00:11,  2.06it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:05<00:05,  1.94s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:15<00:08,  4.37s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:21<00:04,  5.00s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:27<00:00,  4.58s/it]\u001b[A\n",
      " 15%|█▌        | 4/26 [00:29<04:09, 11.33s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:10<00:10, 10.09s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.78s/it]\u001b[A\n",
      " 19%|█▉        | 5/26 [00:45<04:34, 13.07s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:08<00:26,  8.68s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:15<00:15,  7.62s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:22<00:07,  7.39s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:32<00:00,  8.10s/it]\u001b[A\n",
      " 23%|██▎       | 6/26 [01:18<06:35, 19.80s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:05<00:35,  5.96s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:12<00:31,  6.40s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:21<00:29,  7.41s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:28<00:21,  7.16s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:36<00:15,  7.72s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:44<00:07,  7.57s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:53<00:00,  7.70s/it]\u001b[A\n",
      " 27%|██▋       | 7/26 [02:12<09:51, 31.11s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:09<00:59,  9.95s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:18<00:46,  9.37s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:28<00:37,  9.39s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:34<00:24,  8.15s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:41<00:15,  7.78s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:50<00:08,  8.13s/it]\u001b[A\n",
      "100%|██████████| 7/7 [01:00<00:00,  8.67s/it]\u001b[A\n",
      " 35%|███▍      | 9/26 [03:14<07:57, 28.10s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:09<00:19, 10.00s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:19<00:09,  9.77s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:29<00:00,  9.98s/it]\u001b[A\n",
      " 38%|███▊      | 10/26 [03:44<07:40, 28.80s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:06<00:25,  6.42s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:13<00:20,  6.75s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:22<00:15,  7.91s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:31<00:08,  8.19s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:40<00:00,  8.12s/it]\u001b[A\n",
      " 42%|████▏     | 11/26 [04:25<08:08, 32.58s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:05<00:28,  5.74s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:15<00:33,  8.33s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:23<00:24,  8.00s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:29<00:14,  7.39s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:37<00:07,  7.37s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:46<00:00,  7.74s/it]\u001b[A\n",
      " 46%|████▌     | 12/26 [05:13<08:38, 37.00s/it]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/14 [00:09<01:58,  9.08s/it]\u001b[A\n",
      " 14%|█▍        | 2/14 [00:15<01:33,  7.80s/it]\u001b[A\n",
      " 21%|██▏       | 3/14 [00:22<01:20,  7.28s/it]\u001b[A\n",
      " 29%|██▊       | 4/14 [00:28<01:05,  6.56s/it]\u001b[A\n",
      " 36%|███▌      | 5/14 [00:35<01:01,  6.79s/it]\u001b[A\n",
      " 43%|████▎     | 6/14 [00:43<00:56,  7.11s/it]\u001b[A\n",
      " 50%|█████     | 7/14 [00:49<00:49,  7.01s/it]\u001b[A\n",
      " 57%|█████▋    | 8/14 [00:59<00:47,  7.88s/it]\u001b[A\n",
      " 64%|██████▍   | 9/14 [01:06<00:38,  7.68s/it]\u001b[A\n",
      " 71%|███████▏  | 10/14 [01:14<00:30,  7.62s/it]\u001b[A\n",
      " 79%|███████▊  | 11/14 [01:20<00:21,  7.18s/it]\u001b[A\n",
      " 86%|████████▌ | 12/14 [01:28<00:14,  7.37s/it]\u001b[A\n",
      " 93%|█████████▎| 13/14 [01:37<00:08,  8.01s/it]\u001b[A\n",
      "100%|██████████| 14/14 [01:46<00:00,  7.62s/it]\u001b[A\n",
      " 50%|█████     | 13/26 [07:00<12:37, 58.25s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:06<00:13,  6.93s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.90s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:21<00:00,  7.09s/it]\u001b[A\n",
      " 54%|█████▍    | 14/26 [07:22<09:26, 47.24s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.18s/it]\u001b[A\n",
      " 58%|█████▊    | 15/26 [07:28<06:24, 34.92s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:07<00:47,  7.93s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:13<00:32,  6.59s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:20<00:27,  6.85s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:29<00:22,  7.59s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:38<00:16,  8.19s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:47<00:08,  8.35s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:55<00:00,  7.95s/it]\u001b[A\n",
      " 65%|██████▌   | 17/26 [08:24<04:20, 28.96s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:06<00:40,  6.74s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:14<00:35,  7.05s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:20<00:26,  6.67s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:29<00:23,  7.67s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:38<00:16,  8.24s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:48<00:08,  8.88s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:54<00:00,  7.79s/it]\u001b[A\n",
      " 69%|██████▉   | 18/26 [09:19<04:53, 36.68s/it]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/15 [00:08<02:01,  8.69s/it]\u001b[A\n",
      " 13%|█▎        | 2/15 [00:18<02:03,  9.51s/it]\u001b[A\n",
      " 20%|██        | 3/15 [00:28<01:53,  9.46s/it]\u001b[A\n",
      " 27%|██▋       | 4/15 [00:35<01:36,  8.75s/it]\u001b[A\n",
      " 33%|███▎      | 5/15 [00:41<01:16,  7.64s/it]\u001b[A\n",
      " 40%|████      | 6/15 [00:49<01:10,  7.79s/it]\u001b[A\n",
      " 47%|████▋     | 7/15 [00:54<00:55,  6.99s/it]\u001b[A\n",
      " 53%|█████▎    | 8/15 [01:02<00:50,  7.26s/it]\u001b[A\n",
      " 60%|██████    | 9/15 [01:12<00:47,  7.89s/it]\u001b[A\n",
      " 67%|██████▋   | 10/15 [01:20<00:40,  8.19s/it]\u001b[A\n",
      " 73%|███████▎  | 11/15 [01:30<00:34,  8.70s/it]\u001b[A\n",
      " 80%|████████  | 12/15 [01:36<00:23,  7.79s/it]\u001b[A\n",
      " 87%|████████▋ | 13/15 [01:45<00:16,  8.09s/it]\u001b[A\n",
      " 93%|█████████▎| 14/15 [01:54<00:08,  8.46s/it]\u001b[A\n",
      "100%|██████████| 15/15 [02:02<00:00,  8.19s/it]\u001b[A\n",
      " 73%|███████▎  | 19/26 [11:22<07:19, 62.74s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:10<00:30, 10.00s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:18<00:17,  8.92s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:25<00:08,  8.10s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:35<00:00,  8.91s/it]\u001b[A\n",
      " 81%|████████  | 21/26 [11:59<03:12, 38.47s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:10<00:10, 10.06s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:16<00:00,  8.42s/it]\u001b[A\n",
      " 85%|████████▍ | 22/26 [12:16<02:08, 32.15s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:09<00:28,  9.67s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:19<00:19,  9.61s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:28<00:09,  9.50s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.59s/it]\u001b[A\n",
      "100%|██████████| 26/26 [12:52<00:00, 29.73s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(97,123)):\n",
    "    fighterlist_page_first_url = f\"http://ufcstats.com/statistics/fighters?char={chr(i)}\"\n",
    "    download_sequential_pages(fighterlist_page_first_url, fighterlist_html_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03867f8-6108-485b-80bd-0cf0d5185637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_fighter_urls(fighterlist_html_filepath: str) -> list[str]:\n",
    "    with open(fighterlist_html_filepath, \"r\") as f:\n",
    "        html_str = f.read()\n",
    "        \n",
    "    soup = BeautifulSoup(html_str)\n",
    "    rows = soup.find(\"tbody\").find_all(\"tr\")\n",
    "    rows = filter(lambda r: r.find(\"a\") != None, rows)\n",
    "    return lmap(lambda r: r.find(\"a\")[\"href\"], rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68aeef6b-f1c7-4424-b16a-4e3f3971c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fighter_urls(fighterlist_html_filepath: str, outfilename: str) -> list[str]:\n",
    "    fighterlist_files = lfilter(lambda x: x.endswith(\".html\"), os.listdir(fighterlist_html_dir))\n",
    "    \n",
    "    fighter_urls_list = []\n",
    "    for filename in tqdm(fighterlist_files):\n",
    "        filepath = os.path.join(fighterlist_html_dir, filename)\n",
    "        fighter_urls_sublist = extract_fighter_urls(filepath)\n",
    "        fighter_urls_list.extend(fighter_urls_sublist)\n",
    "        \n",
    "    print(f\"Fighter urls list length: {len(fighter_urls_list)}\")\n",
    "    filepath = os.path.join(raw_csv_dir, outfilename)\n",
    "    write_list_to_file(fighter_urls_list, filepath)\n",
    "    return fighter_urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51c6d258-4e29-4e34-9c91-e564aebcd38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:04<00:00, 35.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fighter urls list length: 3565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fighters_url_list = save_fighter_urls(fighterlist_html_dir, \"fighter_urls.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86ea5983-6eab-4a15-af6c-6877cc8c38f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_255553/173468275.py:2: DtypeWarning: Columns (217,219,220) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fights_df = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(mid_dir, \"completed_fights.csv\")\n",
    "fights_df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32dd79b-e162-4751-ae0e-e38dcd79ce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ufcstats.com/fighter-details/cc7040fe76f0ef91\n",
      "1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1376 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m remaining_fighters_urls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(fighters_url_list)\u001b[38;5;241m.\u001b[39mdifference(fighters_urls_in_fight_df))\n\u001b[1;32m     17\u001b[0m save_pages(fighters_urls_in_fight_df, fighters_html_dir)\n\u001b[0;32m---> 19\u001b[0m \u001b[43msave_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_fighters_urls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfighters_html_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36msave_pages\u001b[0;34m(urls, outfolderdir)\u001b[0m\n\u001b[1;32m     25\u001b[0m         session \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     reached_not_downloaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fighters_id_in_fight_df = list(set(fights_df[\"Fighter1 ID\"]).union(fights_df[\"Fighter2 ID\"]))\n",
    "\n",
    "fighters_urls_in_fight_df = lmap(lambda s: f\"http://ufcstats.com/fighter-details/{s}\", fighters_id_in_fight_df)\n",
    "\n",
    "alread_downloaded = lmap(lambda s: f\"http://ufcstats.com/fighter-details/{s.replace('.html','')}\", \n",
    "                         os.listdir(fighters_html_dir))\n",
    "print(alread_downloaded[0])\n",
    "\n",
    "fighters_url_list = set(fighters_url_list).difference(alread_downloaded)\n",
    "print(len(fighters_url_list))\n",
    "fighters_urls_in_fight_df = set(fighters_urls_in_fight_df).difference(alread_downloaded)\n",
    "\n",
    "remaining_fighters_urls = list(set(fighters_url_list).difference(fighters_urls_in_fight_df))\n",
    "\n",
    "\n",
    "\n",
    "save_pages(fighters_urls_in_fight_df, fighters_html_dir)\n",
    "\n",
    "save_pages(remaining_fighters_urls, fighters_html_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090d69e-7198-4178-abd8-db316e96932e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ufc-fight-predictor]",
   "language": "python",
   "name": "conda-env-ufc-fight-predictor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
