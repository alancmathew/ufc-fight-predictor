{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad13894-b03e-4ce7-b215-247cbe4745a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af06c12-2611-4a5e-86b2-cc46d2fe6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f726df-4da8-4562-ace6-da1fb0f58995",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138c6351-2246-48d1-94fe-7e8b51b7a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b770b69e-5a35-4aa3-b86a-90bb02a4ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897cb1d-c18c-4cb5-bd87-d1a0de95944d",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3345d1fe-a2b1-4a40-a713-7776c0669cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_events(df):\n",
    "    res = df[\"location\"].str.extract(r\"(?:(?P<city>.*), )?(?P<state>.*), (?P<country>.*)\")\n",
    "    df = pd.concat([df, res], axis=1)\n",
    "    \n",
    "    df[\"city\"] = df[\"city\"].fillna(\"Unspecified\")\n",
    "    \n",
    "    df[\"name\"] = df[\"name\"].astype(\"string\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%B %d, %Y\", errors=\"coerce\")\\\n",
    "                .fillna(pd.to_datetime(df[\"date\"], format=\"%b %d, %Y\", errors=\"coerce\"))\n",
    "    df[\"id\"] = df[\"url\"].map(lambda s: os.path.split(s)[1])\\\n",
    "                        .map(lambda s: int(str(s), 16))\\\n",
    "                        .astype(\"uint\")\n",
    "    df[\"city\"] = df[\"city\"].astype(\"category\")\n",
    "    df[\"state\"] = df[\"state\"].astype(\"category\")\n",
    "    df[\"country\"] = df[\"country\"].astype(\"category\")\n",
    "    \n",
    "    df = df.drop([\"location\", \"url\"], axis=1)\n",
    "    \n",
    "    df = df.rename({col:f\"event_{col}\" for col in df.columns}, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c278fc1-0347-44fb-b017-0fa72652259e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bba7de8-0832-4826-8971-53355f00cef2",
   "metadata": {},
   "source": [
    "### Fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee94838-bdb2-454b-b687-82da351fec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_weight_class(df):\n",
    "    filepath = os.path.join(dir_dict[\"raw_csv\"], \"completed_fight_urls_weightclasses.csv\")\n",
    "    wc_df = pd.read_csv(filepath)\n",
    "    wc_df[\"Fight ID\"] = \\\n",
    "            wc_df[\"Fight Url\"].map(lambda s: os.path.split(s)[1])\n",
    "    df = df.merge(wc_df.drop(\"Fight Url\", axis=1), on=\"Fight ID\", how=\"left\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a879b5e5-02c6-4dfd-81f5-51e0a29e27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fights(df):\n",
    "    \n",
    "    df = join_weight_class(df) \n",
    "    \n",
    "    to_drop = [col for col in df.columns if \"Details:\" in col] + [\"Event Name\"]\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    \n",
    "    fighter1_cols = [col for col in df.columns if \"Fighter1\" in col]\n",
    "    fighter2_cols = [col for col in df.columns if \"Fighter2\" in col]\n",
    "    general_cols = [col for col in df.columns \\\n",
    "                            if col not in set(fighter1_cols).union(fighter2_cols)]\n",
    "    \n",
    "    df2 = df.copy(deep=True)\n",
    "\n",
    "    df = df.drop(fighter2_cols, axis=1)\n",
    "    df2 = df2.drop(fighter1_cols, axis=1)\n",
    "\n",
    "    # df.columns = lmap(lambda col: col.replace(\"Fighter1_\",\"\"), df.columns)\n",
    "    df.columns = lmap(lambda col: col.replace(\"Fighter1\",\"Fighter\"), df.columns)\n",
    "\n",
    "    # df2.columns = lmap(lambda col: col.replace(\"Fighter2_\",\"\"), df2.columns)\n",
    "    df2.columns = lmap(lambda col: col.replace(\"Fighter2\",\"Fighter\"), df2.columns)\n",
    "\n",
    "    df = pd.concat([df, df2], axis=0)\n",
    "    \n",
    "    df.columns = lmap(lambda col: col.lower().replace(\" \",\"_\").replace(\".\",\"\"), df.columns)\n",
    "    df = df.drop(\"fighter_name\", axis=1)\n",
    "\n",
    "    df[\"fighter_won\"] = (df[\"fighter_status\"] == \"W\").astype(\"uint8\")\n",
    "    df = df.drop(\"fighter_status\", axis=1)\n",
    "    \n",
    "    \n",
    "    df = df.loc[df[\"fighter_overall_kd\"].notnull()]\n",
    "    \n",
    "    # String columns\n",
    "    str_cols = [\"referee\", \"details\"]\n",
    "    df[str_cols] = df[str_cols].astype(\"string\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ID columns\n",
    "    url_cols = [col for col in df.columns if \"url\" in col]\n",
    "    new_id_cols = lmap(lambda s: s.replace(\"url\", \"id\"), url_cols)\n",
    "    df[new_id_cols] = df[url_cols].applymap(lambda s: os.path.split(s)[1])\n",
    "    \n",
    "    id_cols = [col for col in df.columns if \"id\" in col]\n",
    "    df.loc[:, id_cols] = df.loc[:,id_cols].applymap(lambda s: int(str(s), 16)).astype(\"uint\")\n",
    "    \n",
    "    df = df.drop(url_cols, axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Category columns\n",
    "    cat_cols = [\"bout\", \"method\", \"time_format\", \"weight_class\"]\n",
    "    df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Percentage columns\n",
    "    is_pct_col = df.select_dtypes(\"object\").apply(lambda s: s.str.contains(\"%\")).any()\n",
    "    pct_cols = is_pct_col[is_pct_col == True].index.to_list()\n",
    "    df[pct_cols] = df[pct_cols].apply(lambda s: \\\n",
    "                                        s.str.replace(\"%\",\"\").astype(\"float\") / 100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Out-of columns\n",
    "    is_outof_col = df.select_dtypes(\"object\").apply(lambda s: \\\n",
    "                                                    s.str.contains(r\"\\d+ of \\d+\")).any()\n",
    "    outof_cols = is_outof_col[is_outof_col == True].index.to_list()\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for col in outof_cols:\n",
    "            df = pd.concat([df, \\\n",
    "                            df[col].str.extract(f\"(?P<{col}_landed>\\d+) of (?P<{col}_total>\\d+)\")],\n",
    "                           axis=1)\n",
    "\n",
    "    df = df.drop(columns=outof_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Time columns\n",
    "    is_time_col = df.select_dtypes(\"object\").apply(lambda s: s.str.contains(r\"\\d+:\\d+\")).any()\n",
    "    time_cols = is_time_col[is_time_col == True].index.to_list()\n",
    "\n",
    "    def seconds_extrator(row):\n",
    "        return row[0]*60 + row[1]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for col in time_cols:\n",
    "            df[f\"{col}_seconds\"] = \\\n",
    "                        df[col].str.extract(r\"(\\d+):(\\d+)\").astype(\"float\").apply(seconds_extrator, axis=1)\n",
    "        \n",
    "    df = df.drop(columns=time_cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Float columns\n",
    "    float_cols = df.select_dtypes(\"float\").columns.to_list()\n",
    "    df[float_cols] = df[float_cols].astype(\"float\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Round column\n",
    "    df[\"round\"] = df[\"round\"].astype(\"uint8\")\n",
    "    \n",
    "    \n",
    "    rename_dict = {col:f\"fight_{col}\" \\\n",
    "                   for col in df.columns \\\n",
    "                   if all([prefix not in col for prefix in [\"event_\", \"fight_\"]])\n",
    "                      and col != \"fighter_id\"}\n",
    "    \n",
    "    df = df.rename(rename_dict, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99c9f0-d789-44a7-9655-d2f5bf3c0789",
   "metadata": {},
   "source": [
    "### Fighters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb3ea6aa-1de6-49e1-9803-dcfbbff3bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fighters(df):\n",
    "    df.columns = lmap(lambda c: c.lower().replace(\" \", \"_\").replace(\".\",\"\"), df.columns)\n",
    "    \n",
    "    # String columns\n",
    "    str_cols = [\"name\", \"nickname\"]\n",
    "    df[str_cols] = df[str_cols].astype(\"string\")\n",
    "    \n",
    "    # Category columns\n",
    "    cat_cols = [\"stance\"]\n",
    "    df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "    \n",
    "    # ID columns\n",
    "    df[\"fighter_id\"] = df[\"fighter_id\"].map(lambda s: int(str(s), 16))\n",
    "    \n",
    "    wlt = df[\"record\"].str.extract(r\"(?P<wins>\\d+)-(?P<losses>\\d+)-(?P<ties>\\d+)\").astype(\"uint8\")\n",
    "    df = pd.concat([df, wlt], axis=1)\n",
    "    \n",
    "    \n",
    "    # Percentage columns\n",
    "    is_pct_col = df.select_dtypes(\"object\").apply(lambda s: s.str.contains(\"%\")).any()\n",
    "    pct_cols = is_pct_col[is_pct_col == True].index.to_list()\n",
    "    df[pct_cols] = df[pct_cols].apply(lambda s: s.str.replace(\"%\",\"\").astype(\"float\") / 100)\n",
    "    \n",
    "    # date column\n",
    "    df[\"dob\"] = pd.to_datetime(df[\"dob\"], format=\"%b %d, %Y\", errors=\"coerce\")\\\n",
    "                        .fillna(pd.to_datetime(df[\"dob\"], format=\"%B %d, %Y\", errors=\"coerce\"))\n",
    "    \n",
    "    # height column\n",
    "    df[\"height_inches\"] = \\\n",
    "            df[\"height\"].str.extract(\"(\\d+)'(\\d+)\\\"\").astype(\"float\").apply(lambda row: row[0]*12 + row[1], axis=1)\n",
    "    \n",
    "    \n",
    "    # reach column\n",
    "    df[\"reach_inches\"] = \\\n",
    "            df[\"reach\"].str.extract(\"(\\d+)\\\"\").astype(\"float\")\n",
    "    \n",
    "    # weight column\n",
    "    df[\"weight_lbs\"] = df[\"weight\"].str.extract(\"(\\d+) lbs.\").astype(\"float\")\n",
    "    \n",
    "    \n",
    "    to_drop = [\"record\", \"height\", \"reach\", \"weight\"]\n",
    "    \n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5243e84c-00ff-4d6e-8d1b-53000373a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(filename, cleaner_func):\n",
    "    \n",
    "    filepath = os.path.join(dir_dict[\"raw_csv\"], f\"{filename}.csv\")\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "    df = cleaner_func(df)\n",
    "    \n",
    "    filepath = os.path.join(dir_dict[\"clean\"], f\"{filename}.parquet\")\n",
    "    df.to_parquet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d44d96-f2b1-4b96-bb91-b9395f88d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_data():\n",
    "    filename_cleaner_map = {\n",
    "        \"completed_events\": clean_events, \n",
    "        \"upcoming_events\": clean_events, \n",
    "        \"completed_fights\": clean_fights, \n",
    "        \"fighters\": clean_fighters\n",
    "    }\n",
    "    \n",
    "    for filename, cleaner_func in filename_cleaner_map.items():\n",
    "        clean_dataset(filename, cleaner_func)\n",
    "        print(f\"Cleaned {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f60576-945e-4563-9025-bf20a4f09de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    clean_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85ce747-f9a7-4cc5-b78b-31e753f6362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned completed_events\n",
      "Cleaned upcoming_events\n",
      "Cleaned completed_fights\n",
      "Cleaned fighters\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ufc-fight-predictor]",
   "language": "python",
   "name": "conda-env-ufc-fight-predictor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
